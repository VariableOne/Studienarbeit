{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Loss: 1.788346767425537\n",
      "Step 10, Loss: 1.7531473636627197\n",
      "Step 20, Loss: 1.5394386053085327\n",
      "Step 30, Loss: 1.7207698822021484\n",
      "Step 40, Loss: 1.5212738513946533\n",
      "Step 50, Loss: 1.5142273902893066\n",
      "Step 60, Loss: 1.708132266998291\n",
      "Step 70, Loss: 1.653657078742981\n",
      "Step 80, Loss: 1.6463713645935059\n",
      "Step 90, Loss: 1.631257176399231\n",
      "Training abgeschlossen.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import norse.torch as norse\n",
    "import torch.nn as nn\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class STDP_SNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, tau_plus=20.0, tau_minus=20.0, learning_rate=0.005):\n",
    "        super(STDP_SNN, self).__init__()\n",
    "\n",
    "        self.lif1 = norse.LIFCell()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.synapse_weights = torch.randn(hidden_size, input_size).to(device)\n",
    "\n",
    "        # STDP-Parameter\n",
    "        self.tau_plus = tau_plus\n",
    "        self.tau_minus = tau_minus\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def forward(self, x, state):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        spiked, state = self.lif1(x, state)\n",
    "        self.apply_stdp(x, spiked)\n",
    "        x = self.fc2(spiked)\n",
    "\n",
    "        return x, state\n",
    "\n",
    "    def apply_stdp(self, prespike, postsynaptic_spike):\n",
    "        time_difference = postsynaptic_spike - prespike\n",
    "        weight_increase = torch.exp(-torch.abs(time_difference) / self.tau_plus)\n",
    "        weight_decrease = torch.exp(-torch.abs(time_difference) / self.tau_minus)\n",
    "        weight_delta = self.learning_rate * (weight_increase - weight_decrease)\n",
    "        weight_delta_expanded = weight_delta.view(-1, 1)\n",
    "        self.synapse_weights += weight_delta_expanded * self.synapse_weights\n",
    "\n",
    "\n",
    "time_steps = 100\n",
    "input_size = 10\n",
    "hidden_size = 20\n",
    "output_size = 5\n",
    "learning_rate = 0.005\n",
    "\n",
    "snn = STDP_SNN(input_size, hidden_size, output_size).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(snn.parameters(), lr=learning_rate)\n",
    "\n",
    "target = torch.randint(0, output_size, (time_steps, 1)).to(device)\n",
    "for t in range(time_steps):\n",
    "    data = torch.rand(1, input_size).to(device)\n",
    "    output, state = snn(data, None)\n",
    "    loss = criterion(output, target[t].view(-1))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if t % 10 == 0:\n",
    "        print(f\"Step {t}, Loss: {loss.item()}\")\n",
    "\n",
    "print(\"Training abgeschlossen.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

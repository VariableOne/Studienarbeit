{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementierung eines SNN und CNN: Ein Vergleich mit dem MNIST-Datensatz\n",
    "\n",
    "\n",
    "*Author: Ümmühan Ay*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schritt 1: Alle nötigen Imports importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schritt 2: Cuda benutzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schritt 3: Implementierung des SNN und des LIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, learning_rate=0.001, tau_plus=20.0, tau_minus=20.0, tau_mem=10.0, v_rest=-65.0, v_thresh=-50.0, v_reset=-65.0):\n",
    "        super(SNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # Synapsen-Gewichte initialisieren: (input_size, hidden_size)\n",
    "        self.synapse_weights = nn.Parameter(torch.randn(input_size, hidden_size).to(device))\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.tau_plus = tau_plus\n",
    "        self.tau_minus = tau_minus\n",
    "\n",
    "        self.tau_mem = tau_mem  # Membranzeitkonstante\n",
    "        self.v_rest = v_rest  # Ruhepotenzial\n",
    "        self.v_thresh = v_thresh  # Schwellenwert\n",
    "        self.v_reset = v_reset  # Reset-Potenzial\n",
    "\n",
    "        # Membranpotentiale initialisieren\n",
    "        self.v_hidden = torch.full((hidden_size,), self.v_rest, device=\"cuda\")\n",
    "        # STDP Zustände (Spuren für pre- und post-Spikes)\n",
    "        self.pre_trace = torch.zeros(input_size, device=\"cuda\")\n",
    "        self.post_trace = torch.zeros(hidden_size, device=\"cuda\")\n",
    "\n",
    "    def forward(self, x, dt=1e-3):\n",
    "        batch_size, time_steps, _ = x.shape\n",
    "        spikes_out = torch.zeros(batch_size, time_steps, self.hidden_size, device=x.device)\n",
    "\n",
    "        batch_size = x.shape[0]\n",
    "        if self.v_hidden is None or self.v_hidden.shape[0] != batch_size:\n",
    "            self.v_hidden = torch.full((batch_size, self.hidden_size), self.v_rest, device=x.device)\n",
    "\n",
    "        for t in range(time_steps):\n",
    "            z_pre = x[:, t, :]\n",
    "            self.v_hidden = self.v_hidden + (self.v_rest - self.v_hidden) * (dt / self.tau_mem) + torch.matmul(z_pre, self.synapse_weights)\n",
    "            z_post = (self.v_hidden > self.v_thresh).float()\n",
    "            self.v_hidden = torch.where(z_post > 0, self.v_reset, self.v_hidden)\n",
    "            spikes_out[:, t, :] = z_post\n",
    "            self.stdp_update(z_pre, z_post, dt)\n",
    "\n",
    "        output = self.fc2(spikes_out.sum(dim=1))\n",
    "        return output\n",
    "\n",
    "    def stdp_update(self, z_pre, z_post, dt):\n",
    "        self.pre_trace = (1 - dt / self.tau_plus) * self.pre_trace + z_pre.mean(dim=0)\n",
    "        self.post_trace = (1 - dt / self.tau_minus) * self.post_trace + z_post.mean(dim=0)\n",
    "\n",
    "        hebbian = torch.ger(self.post_trace, self.pre_trace)\n",
    "        anti_hebbian = torch.ger(self.pre_trace, self.post_trace)\n",
    "\n",
    "        dw = self.learning_rate * (hebbian - anti_hebbian.T)\n",
    "        dw = torch.clamp(dw, -1.0, 1.0)\n",
    "        self.synapse_weights.data += dw.T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schritt 4: MNIST-Datensatz laden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test mit MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test mit Kanji-Datensatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "batch_size = 32\n",
    "time_steps = 10\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])\n",
    "])\n",
    "\n",
    "# CIFAR-10 Dataset laden (train und test)\n",
    "train_dataset = datasets.CIFAR10(root='./cifar-10', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='./cifar-10', train=False, download=False, transform=transform)\n",
    "# Nur 900 Trainingsdaten & 100 Testdaten\n",
    "train_subset = Subset(train_dataset, range(900))\n",
    "test_subset = Subset(test_dataset, range(100))\n",
    "# Trainings- und Test-Dataloader\n",
    "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "def image_to_spikes(images, time_steps, threshold=0.5):\n",
    "    spikes = torch.zeros((images.size(0), time_steps, images.size(1)), device=images.device)\n",
    "    for t in range(time_steps):\n",
    "        spikes[:, t, :] = (images > threshold).float()\n",
    "    return spikes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schritt 5: CNN erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "        # Dropout nach der ersten Fully Connected Layer\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        # BatchNorm für Convolutional Layer\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional Layers mit BatchNorm und ReLU\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))   # 32x32 → 16x16\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))   # 16x16 → 8x8\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))   # 8x8 → 4x4\n",
    "        \n",
    "        # Flatten the tensor\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully Connected Layers mit Dropout\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)  # Dropout nach fc1\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Hyperparameter, Loss-Funktion und Optimizer definieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter\n",
    "input_size = 32 * 32 * 3  # Für CIFAR-10 Bilder\n",
    "hidden_size = 512\n",
    "output_size = 10\n",
    "epochs = 100\n",
    "time_steps = 10\n",
    "\n",
    "snn_model = SNN(input_size=input_size, hidden_size=hidden_size, output_size=output_size).to(device)\n",
    "cnn_model = SimpleCNN().to(device)\n",
    "\n",
    "snn_optimizer = torch.optim.Adam(snn_model.parameters(), lr=0.001)\n",
    "cnn_optimizer = torch.optim.Adam(cnn_model.parameters(), lr=0.001)\n",
    "\n",
    "snn_loss_fn = torch.nn.CrossEntropyLoss()\n",
    "cnn_loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "torch.cuda.synchronize()\n",
    "start_memory = torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Training SNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNN trainieren\n",
    "for epoch in range(epochs):\n",
    "    snn_model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images = images.view(images.size(0), -1)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        spikes = image_to_spikes(images, time_steps)\n",
    "\n",
    "        outputs = snn_model(spikes)\n",
    "        loss = snn_loss_fn(outputs, labels.to(device))\n",
    "\n",
    "        snn_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        snn_optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{epochs}], SNN Loss: {running_loss/len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.synchronize()\n",
    "end = time.time()\n",
    "end_memory = torch.cuda.max_memory_allocated()\n",
    "\n",
    "print(f\"Trainingszeit: {end - start:.2f} Sekunden\")\n",
    "print(f\"Maximale GPU-Speichernutzung: {end_memory / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. CNN trainieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN trainieren\n",
    "for epoch in range(epochs):\n",
    "    cnn_model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = cnn_model(images)\n",
    "        \n",
    "        cnn_loss = cnn_loss_fn(outputs, labels)\n",
    "        cnn_optimizer.zero_grad()\n",
    "        cnn_loss.backward()\n",
    "        cnn_optimizer.step()\n",
    "        \n",
    "        running_loss += cnn_loss.item()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{epochs}], CNN Loss: {running_loss/len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.synchronize()\n",
    "end = time.time()\n",
    "end_memory = torch.cuda.max_memory_allocated()\n",
    "\n",
    "print(f\"Trainingszeit: {end - start:.2f} Sekunden\")\n",
    "print(f\"Maximale GPU-Speichernutzung: {end_memory / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. SNN Evaluieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "snn_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_values = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.view(images.size(0), -1).to(device)\n",
    "        spikes = image_to_spikes(images, time_steps)\n",
    "        spikes = spikes.to(device)\n",
    "        \n",
    "        outputs = snn_model(spikes)\n",
    "        loss = snn_loss_fn(outputs, labels.to(device))\n",
    "        loss_values.append(loss.item())  # Speichern des Verlusts\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.to(device)).sum().item()\n",
    "\n",
    "# Plot der Verlustwerte\n",
    "plt.plot(loss_values, label=\"Loss (Cross-Entropy)\")\n",
    "plt.xlabel(\"Batch-Index\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Verlustkurve während des Tests\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Berechnung der Genauigkeit\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy (SNN): {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. CNN Evaluieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_values = []\n",
    "cnn_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = cnn_model(images)\n",
    "        loss = cnn_loss_fn(outputs, labels)\n",
    "        loss_values.append(loss.item())\n",
    "    \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.to(device)).sum().item()\n",
    "\n",
    "# Plot der Verlustkurve\n",
    "plt.plot(loss_values, label=\"Loss (Cross-Entropy)\")\n",
    "plt.xlabel(\"Batch-Index\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Verlustfunktion während des Tests\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Genauigkeit ausgeben\n",
    "print(f'Accuracy (CNN): {100 * correct / total:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

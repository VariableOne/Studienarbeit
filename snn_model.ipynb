{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementierung eines SNN und CNN: Ein Vergleich mit dem CIFAR-10-Datensatz\n",
    "\n",
    "\n",
    "*Author: Ümmühan Ay*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schritt 1: Alle nötigen Imports importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schritt 2: Cuda benutzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schritt 3: Implementierung des SNN und des LIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurrogateSpike(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ctx.save_for_backward(input)\n",
    "        return (input > 0).float()\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, = ctx.saved_tensors\n",
    "        surrogate_grad = torch.exp(-input.abs())  # Glatte Ableitung\n",
    "        return grad_output * surrogate_grad\n",
    "\n",
    "spike_fn = SurrogateSpike.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, v_rest=-65.0, v_thresh=-50.0, v_reset=-65.0, tau_mem=10.0):\n",
    "        super(SNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.v_rest = v_rest\n",
    "        self.v_thresh = v_thresh\n",
    "        self.v_reset = v_reset\n",
    "        self.tau_mem = tau_mem\n",
    "\n",
    "        self.synapse_weights = nn.Parameter(torch.randn(input_size, hidden_size) * 0.1)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_norm = nn.BatchNorm1d(hidden_size)\n",
    "\n",
    "    def forward(self, x, dt=1e-3):\n",
    "        batch_size, time_steps, _ = x.shape\n",
    "        v_hidden = torch.full((batch_size, self.hidden_size), self.v_rest, device=x.device)\n",
    "        spikes_out = torch.zeros(batch_size, time_steps, self.hidden_size, device=x.device)\n",
    "\n",
    "        for t in range(time_steps):\n",
    "            z_pre = x[:, t, :]  # (B, input_size)\n",
    "            v_hidden += (self.v_rest - v_hidden) * (dt / self.tau_mem) + torch.matmul(z_pre, self.synapse_weights)\n",
    "            z_post = spike_fn(v_hidden - self.v_thresh)\n",
    "            v_hidden = torch.where(z_post > 0, torch.tensor(self.v_reset, device=x.device), v_hidden)\n",
    "            spikes_out[:, t, :] = z_post\n",
    "\n",
    "        spikes_sum = spikes_out.sum(dim=1)\n",
    "        spikes_bn = self.batch_norm(spikes_sum)\n",
    "        output = self.fc2(spikes_bn)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schritt 4: MNIST-Datensatz laden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test mit MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test mit Kanji-Datensatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Bilder werden zu Tensors\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalisierung für CIFAR-10\n",
    "])\n",
    "\n",
    "# CIFAR-10 Dataset laden (train und test)\n",
    "train_dataset = datasets.CIFAR10(root='./cifar-10', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='./cifar-10', train=False, download=False, transform=transform)\n",
    "# # Nur 900 Trainingsdaten & 100 Testdaten\n",
    "train_subset = Subset(train_dataset, range(9000))\n",
    "test_subset = Subset(test_dataset, range(1000))\n",
    "# Trainings- und Test-Dataloader\n",
    "train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_subset, batch_size=32, shuffle=False)\n",
    "\n",
    "def image_to_spikes(images, time_steps, threshold=0.0):\n",
    "    images = images.view(images.size(0), -1)  # (B, 3072)\n",
    "    spikes = torch.zeros((images.size(0), time_steps, images.size(1)), device=images.device)\n",
    "    for t in range(time_steps):\n",
    "        spikes[:, t, :] = (images > threshold).float()\n",
    "    return spikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schritt 5: CNN erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "        # BatchNorm für Convolutional Layer\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional Layers mit BatchNorm und ReLU\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))   # 32x32 → 16x16\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))   # 16x16 → 8x8\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))   # 8x8 → 4x4\n",
    "        \n",
    "        # Flatten the tensor\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully Connected Layers mit Dropout\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Hyperparameter, Loss-Funktion und Optimizer definieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter\n",
    "input_size = 32 * 32 * 3\n",
    "hidden_size = 512\n",
    "output_size = 10\n",
    "epochs = 20\n",
    "time_steps = 50\n",
    "\n",
    "snn_model = SNN(input_size=input_size, hidden_size=hidden_size, output_size=output_size).to(device)\n",
    "cnn_model = SimpleCNN().to(device)\n",
    "\n",
    "snn_optimizer = torch.optim.Adam(snn_model.parameters(), lr=0.001)\n",
    "cnn_optimizer = torch.optim.Adam(cnn_model.parameters(), lr=0.001)\n",
    "\n",
    "snn_loss_fn = torch.nn.CrossEntropyLoss()\n",
    "cnn_loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "torch.cuda.synchronize()\n",
    "start_memory = torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Training SNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Spikes generieren\n",
    "        spike_input = image_to_spikes(images, time_steps, threshold=0.02)\n",
    "\n",
    "        # Forward + Loss\n",
    "        outputs = snn_model(spike_input)\n",
    "        loss = snn_loss_fn(outputs, labels)\n",
    "\n",
    "        # Backward + Optimierung\n",
    "        snn_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        snn_optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.synchronize()\n",
    "end = time.time()\n",
    "end_memory = torch.cuda.max_memory_allocated()\n",
    "\n",
    "print(f\"Trainingszeit: {end - start:.2f} Sekunden\")\n",
    "print(f\"Maximale GPU-Speichernutzung: {end_memory / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. CNN trainieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.StepLR(cnn_optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    cnn_model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        cnn_optimizer.zero_grad()\n",
    "        outputs = cnn_model(images)\n",
    "        \n",
    "        cnn_loss = cnn_loss_fn(outputs, labels)\n",
    "        cnn_loss.backward()\n",
    "        cnn_optimizer.step()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        running_loss += cnn_loss.item()\n",
    "\n",
    "    # Lernratenplaner verwenden\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], CNN Loss: {running_loss/len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.synchronize()\n",
    "end = time.time()\n",
    "end_memory = torch.cuda.max_memory_allocated()\n",
    "\n",
    "print(f\"Trainingszeit: {end - start:.2f} Sekunden\")\n",
    "print(f\"Maximale GPU-Speichernutzung: {end_memory / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. SNN Evaluieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "snn_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_values = []\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.view(images.size(0), -1).to(device)\n",
    "        spikes = image_to_spikes(images, time_steps).to(device)\n",
    "\n",
    "        outputs = snn_model(spikes)\n",
    "        loss = snn_loss_fn(outputs, labels.to(device))\n",
    "        loss_values.append(loss.item())\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.to(device)).sum().item()\n",
    "\n",
    "        # Wichtig: Auf CPU bringen und zu Listen hinzufügen\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "plt.plot(loss_values, label=\"Loss (Cross-Entropy)\")\n",
    "plt.xlabel(\"Batch-Index\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Verlustfunktion während des Tests\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Accuracy berechnen\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy (SNN): {accuracy:.2f}%')\n",
    "\n",
    "# Optional: target names, z. B. für KMNIST (0–9)\n",
    "class_names = [str(i) for i in range(10)]\n",
    "\n",
    "# Classification Report\n",
    "report = classification_report(\n",
    "    all_labels,\n",
    "    all_preds,\n",
    "    target_names=class_names,\n",
    "    zero_division=0\n",
    ")\n",
    "f_stat, p_val = f_oneway(all_labels, all_labels)\n",
    "print(f\"F = {f_stat:.3f}, p = {p_val:.3f}\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. CNN Evaluieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "loss_values = []\n",
    "cnn_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = cnn_model(images)\n",
    "        loss = cnn_loss_fn(outputs, labels)\n",
    "        loss_values.append(loss.item())\n",
    "    \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Plot der Verlustkurve\n",
    "plt.plot(loss_values, label=\"Loss (Cross-Entropy)\")\n",
    "plt.xlabel(\"Batch-Index\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Verlustfunktion während des Tests\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "precision = precision_score(all_labels, all_preds, average='macro')\n",
    "recall = recall_score(all_labels, all_preds, average='macro')\n",
    "f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "print(f'Accuracy (CNN): {100 * correct / total:.2f}%')\n",
    "print(f'Precision (macro): {precision:.4f}')\n",
    "print(f'Recall (macro):    {recall:.4f}')\n",
    "print(f'F1-Score (macro):  {f1:.4f}')\n",
    "\n",
    "report = classification_report(all_labels, all_preds, zero_division=0)\n",
    "f_stat, p_val = f_oneway(all_labels, all_labels)\n",
    "print(f\"F = {f_stat:.3f}, p = {p_val:.3f}\")\n",
    "print(report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

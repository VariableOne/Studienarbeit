{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementierung eines SNN und CNN: Ein Vergleich mit dem MNIST-Datensatz\n",
    "\n",
    "\n",
    "*Author: Ümmühan Ay*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schritt 1: Alle nötigen Imports importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schritt 2: Cuda und GPU als device festlegen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schritt 3: Implementierung des SNN und des LIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, learning_rate=0.001, tau_plus=20.0, tau_minus=20.0, tau_mem=10.0, v_rest=-65.0, v_thresh=-50.0, v_reset=-65.0):\n",
    "        super(SNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # Synapsen-Gewichte initialisieren: (input_size, hidden_size)\n",
    "        self.synapse_weights = nn.Parameter(torch.randn(input_size, hidden_size).to(device))\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.tau_plus = tau_plus\n",
    "        self.tau_minus = tau_minus\n",
    "\n",
    "        self.tau_mem = tau_mem  # Membranzeitkonstante\n",
    "        self.v_rest = v_rest  # Ruhepotenzial\n",
    "        self.v_thresh = v_thresh  # Schwellenwert\n",
    "        self.v_reset = v_reset  # Reset-Potenzial\n",
    "\n",
    "        # Membranpotentiale initialisieren\n",
    "        self.v_hidden = torch.full((hidden_size,), self.v_rest, device=\"cuda\")\n",
    "        # STDP Zustände (Spuren für pre- und post-Spikes)\n",
    "        self.pre_trace = torch.zeros(input_size, device=\"cuda\")\n",
    "        self.post_trace = torch.zeros(hidden_size, device=\"cuda\")\n",
    "\n",
    "    def forward(self, x, dt=1e-3):\n",
    "        batch_size, time_steps, _ = x.shape\n",
    "        dt_tensor = torch.tensor(dt, device=x.device)\n",
    "        spikes_out = torch.zeros(batch_size, time_steps, self.hidden_size, device=x.device)\n",
    "\n",
    "        batch_size = x.shape[0]\n",
    "        if self.v_hidden is None or self.v_hidden.shape[0] != batch_size:\n",
    "            self.v_hidden = torch.full((batch_size, self.hidden_size), self.v_rest, device=x.device)\n",
    "\n",
    "        for t in range(time_steps):\n",
    "            z_pre = x[:, t, :]\n",
    "            self.v_hidden = self.v_hidden + (self.v_rest - self.v_hidden) * (dt / self.tau_mem) + torch.matmul(z_pre, self.synapse_weights)\n",
    "            z_post = (self.v_hidden > self.v_thresh).float()\n",
    "            self.v_hidden = torch.where(z_post > 0, self.v_reset, self.v_hidden)\n",
    "            spikes_out[:, t, :] = z_post\n",
    "            self.stdp_update(z_pre, z_post, dt)\n",
    "\n",
    "        output = self.fc2(spikes_out.sum(dim=1))\n",
    "        return output\n",
    "\n",
    "    def stdp_update(self, z_pre, z_post, dt):\n",
    "        self.pre_trace = (1 - dt / self.tau_plus) * self.pre_trace + z_pre.mean(dim=0)\n",
    "        self.post_trace = (1 - dt / self.tau_minus) * self.post_trace + z_post.mean(dim=0)\n",
    "\n",
    "        hebbian = torch.ger(self.post_trace, self.pre_trace)\n",
    "        anti_hebbian = torch.ger(self.pre_trace, self.post_trace)\n",
    "\n",
    "        dw = self.learning_rate * (hebbian - anti_hebbian.T)\n",
    "        dw = torch.clamp(dw, -1.0, 1.0)\n",
    "        self.synapse_weights.data += dw.T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schritt 4: MNIST-Datensatz laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alter Minst datensatz\n",
    "\n",
    "# transform = transforms.Compose([transforms.ToTensor()])\n",
    "# train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "# subset_size = 900\n",
    "# train_dataset = torch.utils.data.Subset(train_dataset, range(subset_size))\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "# test_subset_size = 100\n",
    "# test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "# test_dataset = torch.utils.data.Subset(test_dataset, range(test_subset_size))\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load('kmnist-train-imgs.npz')['arr_0']  # 60,000 Bilder\n",
    "train_labels = np.load('kmnist-train-labels.npz')['arr_0']  # 60,000 Labels\n",
    "\n",
    "test_data = np.load('kmnist-test-imgs.npz')['arr_0']  # 10,000 Bilder\n",
    "test_labels = np.load('kmnist-test-labels.npz')['arr_0']  # 10,000 Labels\n",
    "\n",
    "class KuzushijiMNISTDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return torch.tensor(image, dtype=torch.float32), torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "time_steps = 50\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = KuzushijiMNISTDataset(train_data, train_labels, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_dataset = KuzushijiMNISTDataset(test_data, test_labels, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "def image_to_spikes(images, time_steps):\n",
    "    spikes = torch.bernoulli(images.unsqueeze(1).expand(-1, time_steps, -1))\n",
    "    return spikes.float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schritt 5: CNN erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = F.relu(self.fc1(x)) \n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Hyperparameter, Loss-Funktion und Optimizer definieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter\n",
    "input_size = 280 * 280\n",
    "hidden_size = 512\n",
    "output_size = 10\n",
    "epochs = 5\n",
    "time_steps = 10\n",
    "\n",
    "snn_model = SNN(input_size=28*28, hidden_size=512, output_size=10).to(device)\n",
    "cnn_model = SimpleCNN().to(device)\n",
    "\n",
    "snn_optimizer = torch.optim.Adam(snn_model.parameters(), lr=0.001)\n",
    "cnn_optimizer = torch.optim.Adam(cnn_model.parameters(), lr=0.001)\n",
    "\n",
    "snn_loss_fn = torch.nn.CrossEntropyLoss()\n",
    "cnn_loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Training SNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ümmühan\\AppData\\Local\\Temp\\ipykernel_14668\\364495341.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(image, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], SNN Loss: 1.0459\n"
     ]
    }
   ],
   "source": [
    "# SNN trainieren\n",
    "for epoch in range(epochs):\n",
    "    snn_model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images = images.view(images.size(0), -1).to(device)\n",
    "        spikes = image_to_spikes(images, time_steps)\n",
    "\n",
    "        outputs = snn_model(spikes)\n",
    "        loss = snn_loss_fn(outputs, labels.to(device))\n",
    "\n",
    "        snn_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        snn_optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{epochs}], SNN Loss: {running_loss/len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. CNN trainieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN trainieren\n",
    "for epoch in range(epochs):\n",
    "    cnn_model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = cnn_model(images)\n",
    "        \n",
    "        cnn_loss = cnn_loss_fn(outputs, labels)\n",
    "        cnn_optimizer.zero_grad()\n",
    "        cnn_loss.backward()\n",
    "        cnn_optimizer.step()\n",
    "        \n",
    "        running_loss += cnn_loss.item()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{epochs}], CNN Loss: {running_loss/len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. SNN Evaluieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNN test\n",
    "snn_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.view(images.size(0), -1).to(device)\n",
    "        spikes = image_to_spikes(images, time_steps)\n",
    "        spikes = spikes.to(device)\n",
    "        \n",
    "        outputs = snn_model(spikes)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.to(device)).sum().item()\n",
    "        \n",
    "print(f'Accuracy (SNN): {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. CNN Evaluieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN test\n",
    "cnn_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = cnn_model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "print(f'Accuracy (CNN): {100 * correct / total:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

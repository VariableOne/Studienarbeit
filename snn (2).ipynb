{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementierung eines SNN und CNN: Ein Vergleich mit dem MNIST-Datensatz\n",
    "\n",
    "\n",
    "*Author: Ümmühan Ay*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schritt 1: Alle nötigen Imports importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import jit\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schritt 2: Cuda und GPU als device festlegen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch-Version: 2.6.0+cpu\n",
      "CUDA verfügbar: False\n",
      "CUDA-Version in PyTorch: None\n",
      "Gefundene GPUs: 0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import torch\n",
    "print(\"PyTorch-Version:\", torch.__version__)\n",
    "print(\"CUDA verfügbar:\", torch.cuda.is_available())\n",
    "print(\"CUDA-Version in PyTorch:\", torch.version.cuda)\n",
    "print(\"Gefundene GPUs:\", torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU-Name:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schritt 3: Implementierung des SNN und des LIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, learning_rate=0.01, tau_plus=20.0, tau_minus=20.0, tau_mem=10.0, v_rest=-65.0, v_thresh=-50.0, v_reset=-65.0):\n",
    "        super(SNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.synapse_weights = nn.Parameter(torch.randn(input_size, hidden_size) * 0.01)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.tau_plus = tau_plus\n",
    "        self.tau_minus = tau_minus\n",
    "\n",
    "        self.tau_mem = tau_mem  # Membranzeitkonstante\n",
    "        self.v_rest = v_rest  # Ruhepotenzial\n",
    "        self.v_thresh = v_thresh  # Schwellenwert\n",
    "        self.v_reset = v_reset  # Reset-Potenzial\n",
    "\n",
    "        # Membranpotentiale initialisieren\n",
    "        self.v_hidden = torch.full((hidden_size,), self.v_rest, device=\"cuda\")\n",
    "\n",
    "        # STDP Zustände (Spuren für pre- und post-Spikes)\n",
    "        self.pre_trace = torch.zeros(input_size, device=\"cuda\")\n",
    "        self.post_trace = torch.zeros(hidden_size, device=\"cuda\")\n",
    "\n",
    "    def forward(self, x, dt=1e-3):\n",
    "        batch_size, time_steps, _ = x.shape  \n",
    "        dt_tensor = torch.tensor(dt, device=x.device)\n",
    "        spikes_out = torch.zeros(batch_size, time_steps, self.hidden_size, device=x.device)\n",
    "\n",
    "        for t in range(time_steps):\n",
    "            z_pre = x[:, t, :]\n",
    "            # Update des Membranpotentials mit Leck (LIF-Modell)\n",
    "            self.v_hidden = self.v_hidden * torch.exp(-dt_tensor / self.tau_mem) + torch.matmul(z_pre, self.synapse_weights)\n",
    "            # Spiking: Neuron feuert, wenn Membranpotential den Schwellenwert überschreitet\n",
    "            z_post = (self.v_hidden > self.v_thresh).float()\n",
    "            # Reset des Membranpotentials nach dem Spike\n",
    "            self.v_hidden = torch.where(z_post > 0, self.v_reset, self.v_hidden)\n",
    "            spikes_out[:, t, :] = z_post\n",
    "            self.stdp_update(z_pre, z_post, dt)\n",
    "\n",
    "        output = self.fc2(spikes_out.mean(dim=1))  \n",
    "        return output\n",
    "\n",
    "    def stdp_update(self, z_pre, z_post, dt):\n",
    "        self.pre_trace = (1 - dt / self.tau_plus) * self.pre_trace + z_pre.mean(dim=0)\n",
    "        self.post_trace = (1 - dt / self.tau_minus) * self.post_trace + z_post.mean(dim=0)\n",
    "        hebbian = torch.ger(self.post_trace, self.pre_trace)  # (hidden_size, input_size)\n",
    "        anti_hebbian = torch.ger(self.pre_trace, self.post_trace)  # (input_size, hidden_size)\n",
    "        # STDP-Gewichtsänderung\n",
    "        dw = self.learning_rate * (hebbian - anti_hebbian.T)  \n",
    "        # Gewichte aktualisieren und begrenzen\n",
    "        self.synapse_weights.data += dw.T  # Transponieren, damit es (784, 1000) hat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schritt 4: MNIST-Datensatz laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "time_steps = 50\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "def image_to_spikes(images, time_steps):\n",
    "    batch_size, num_inputs = images.shape\n",
    "    \n",
    "    images = images / 255.0\n",
    "    random_values = torch.rand(batch_size, time_steps, num_inputs, device=images.device)\n",
    "\n",
    "    spikes = (random_values < images.unsqueeze(1)).float()\n",
    "    \n",
    "    return spikes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schritt 5: CNN erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # 1 input channel (grayscale), 32 output channels, 3x3 kernel\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3)  \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # Fully connected layer with 32*13*13 input features (after conv + pool) and 10 output classes\n",
    "        self.fc1 = nn.Linear(32 * 13 * 13, 10)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # Convolution + ReLU + MaxPooling\n",
    "        # Flatten the output of the conv layer for the fully connected layer\n",
    "        x = x.view(-1, 32 * 13 * 13)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Hyperparameter, Loss-Funktion und Optimizer definieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m p = \u001b[32m0.5\u001b[39m\n\u001b[32m     10\u001b[39m device = torch.device(\u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m snn_model = \u001b[43mSNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m28\u001b[39;49m\u001b[43m*\u001b[49m\u001b[32;43m28\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m.to(device)\n\u001b[32m     12\u001b[39m cnn_model = SimpleCNN().to(device)\n\u001b[32m     13\u001b[39m snn_optimizer = torch.optim.Adam(snn_model.parameters(), lr=\u001b[32m0.001\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mSNN.__init__\u001b[39m\u001b[34m(self, input_size, hidden_size, output_size, learning_rate, tau_plus, tau_minus, tau_mem, v_rest, v_thresh, v_reset)\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mself\u001b[39m.v_reset = v_reset  \u001b[38;5;66;03m# Reset-Potenzial\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Membranpotentiale initialisieren\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28mself\u001b[39m.v_hidden = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfull\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mv_rest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# STDP Zustände (Spuren für pre- und post-Spikes)\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28mself\u001b[39m.pre_trace = torch.zeros(input_size, device=\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\cuda\\__init__.py:310\u001b[39m, in \u001b[36m_lazy_init\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    305\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    306\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    307\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmultiprocessing, you must use the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mspawn\u001b[39m\u001b[33m'\u001b[39m\u001b[33m start method\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    308\u001b[39m     )\n\u001b[32m    309\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch._C, \u001b[33m\"\u001b[39m\u001b[33m_cuda_getDeviceCount\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTorch not compiled with CUDA enabled\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    312\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[32m    313\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    314\u001b[39m     )\n",
      "\u001b[31mAssertionError\u001b[39m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# Hyperparameter\n",
    "input_size = 28 * 28\n",
    "hidden_size = 1000\n",
    "output_size = 10\n",
    "learning_rate = 0.001\n",
    "epochs = 5\n",
    "time_steps = 50\n",
    "p = 0.5\n",
    "\n",
    "device = torch.device('cuda')\n",
    "snn_model = SNN(input_size=28*28, hidden_size=1000, output_size=10).to(device)\n",
    "cnn_model = SimpleCNN().to(device)\n",
    "snn_optimizer = torch.optim.Adam(snn_model.parameters(), lr=0.001)\n",
    "cnn_optimizer = torch.optim.Adam(cnn_model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "# Function to average spikes over time\n",
    "def average_spikes(spikes, time_steps):\n",
    "    return spikes.mean(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Training SNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[199]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m images = images.view(images.size(\u001b[32m0\u001b[39m), -\u001b[32m1\u001b[39m).to(device)  \u001b[38;5;66;03m# Flatten (28x28 → 784)\u001b[39;00m\n\u001b[32m      7\u001b[39m spikes = image_to_spikes(images, time_steps)  \u001b[38;5;66;03m# Spikes generieren\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m outputs = \u001b[43msnn_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspikes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m loss = loss_fn(outputs, labels.to(device))\n\u001b[32m     12\u001b[39m snn_optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[190]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mSNN.forward\u001b[39m\u001b[34m(self, x, dt)\u001b[39m\n\u001b[32m     35\u001b[39m z_pre = x[:, t, :]\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# Update des Membranpotentials mit Leck (LIF-Modell)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[38;5;28mself\u001b[39m.v_hidden = \u001b[38;5;28mself\u001b[39m.v_hidden * \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[43mdt_tensor\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtau_mem\u001b[49m\u001b[43m)\u001b[49m + torch.matmul(z_pre, \u001b[38;5;28mself\u001b[39m.synapse_weights)\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Spiking: Neuron feuert, wenn Membranpotential den Schwellenwert überschreitet\u001b[39;00m\n\u001b[32m     41\u001b[39m z_post = (\u001b[38;5;28mself\u001b[39m.v_hidden > \u001b[38;5;28mself\u001b[39m.v_thresh).float()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    snn_model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images = images.view(images.size(0), -1).to(device)  # Flatten (28x28 → 784)\n",
    "        spikes = image_to_spikes(images, time_steps)  # Spikes generieren\n",
    "\n",
    "        outputs = snn_model(spikes)\n",
    "        loss = loss_fn(outputs, labels.to(device))\n",
    "\n",
    "        snn_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        snn_optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{epochs}], SNN Loss: {running_loss/len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. CNN trainieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], CNN Loss: 0.2893\n",
      "Epoch [2/5], CNN Loss: 0.1030\n",
      "Epoch [3/5], CNN Loss: 0.0728\n",
      "Epoch [4/5], CNN Loss: 0.0588\n",
      "Epoch [5/5], CNN Loss: 0.0487\n"
     ]
    }
   ],
   "source": [
    "# Training CNN\n",
    "for epoch in range(epochs):\n",
    "    cnn_model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images = images.view(images.size(0), -1)\n",
    "        spikes = image_to_spikes(images, time_steps)\n",
    "        averaged_spikes = average_spikes(spikes, time_steps)\n",
    "        spikes_for_cnn = averaged_spikes.view(averaged_spikes.size(0), 1, 28, 28)\n",
    "        \n",
    "        outputs = cnn_model(spikes_for_cnn)\n",
    "        \n",
    "        loss = loss_fn(outputs, labels)\n",
    "        cnn_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        cnn_optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{epochs}], CNN Loss: {running_loss/len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. SNN Evaluieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (SNN): 58.75%\n"
     ]
    }
   ],
   "source": [
    "# Testing SNN\n",
    "snn_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.view(images.size(0), -1)\n",
    "        spikes = image_to_spikes(images, time_steps)\n",
    "        outputs = snn_model(spikes)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(f'Accuracy (SNN): {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. CNN Evaluieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (CNN): 97.76%\n"
     ]
    }
   ],
   "source": [
    "# Testing CNN\n",
    "cnn_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.view(images.size(0), -1)\n",
    "        spikes = image_to_spikes(images, time_steps)\n",
    "        averaged_spikes = average_spikes(spikes, time_steps)\n",
    "        spikes_for_cnn = averaged_spikes.view(averaged_spikes.size(0), 1, 28, 28)\n",
    "        outputs = cnn_model(spikes_for_cnn)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(f'Accuracy (CNN): {100 * correct / total:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
